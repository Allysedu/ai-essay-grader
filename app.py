import streamlit as st
import pandas as pd
import pdfplumber
import google.generativeai as genai
import time
import re
import json
import datetime
import os
import base64
import io
import zipfile
import docx
from docx.shared import Pt
from docx.oxml.ns import qn

# --- ğŸ–¥ï¸ ì•± ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤) ---
st.set_page_config(page_title="AI ì—ì„¸ì´ í‰ê°€ í”Œë«í¼", page_icon="ğŸ¤–", layout="wide")

# --- ğŸ” 1. ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ê¸°ëŠ¥ ---
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state.password_correct = False
    if not st.session_state.password_correct:
        st.header("ğŸ”’ ë¡œê·¸ì¸")
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", key="password_input")
        if st.button("ë¡œê·¸ì¸", key="login_button"):
            correct_password = st.secrets.get("APP_PASSWORD", "skwlals25") # ğŸ”‘ ì—¬ê¸°ì— ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
            if password == correct_password:
                st.session_state.password_correct = True
                st.rerun()
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    return True

# --- ğŸ§  ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ (ë§ˆí¬ë‹¤ìš´) ---
def generate_report_markdown(result_data):
    """í•™ìƒ í•œ ëª…ì˜ í‰ê°€ ê²°ê³¼ë¥¼ í™”ë©´ í‘œì‹œìš© ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    parsed_data = result_data.get('í‰ê°€ê²°ê³¼_ë¶„ì„', {})
    report = [
        f"#### ğŸ’¬ ì¢…í•© í‰ê°€",
        f"{parsed_data.get('ì¢…í•© í‰ê°€', 'ë‚´ìš© ì—†ìŒ')}",
        "---",
        f"#### ğŸ’¯ í•­ëª©ë³„ ìƒì„¸ í‰ê°€"
    ]
    itemized_scores = parsed_data.get('í•­ëª©ë³„ í‰ê°€', {})
    if itemized_scores:
        for item_name, details in itemized_scores.items():
            report.append(f"**- {item_name} ({details.get('ì ìˆ˜', 'N/A')} / {details.get('ë°°ì ', 'N/A')})**")
            report.append(f"> {details.get('ì´ìœ ', 'ë‚´ìš© ì—†ìŒ')}")
    else:
        report.append("ìƒì„¸ í‰ê°€ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return "\n".join(report)

# --- ğŸ§  ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ (ì›Œë“œ .docx) ---
def generate_report_docx(result_data, eval_name, eval_date):
    """í•™ìƒ í•œ ëª…ì˜ í‰ê°€ ê²°ê³¼ë¥¼ ì›Œë“œ(.docx) íŒŒì¼ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    document = docx.Document()
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    style = document.styles['Normal']
    style.font.name = 'Malgun Gothic'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'Malgun Gothic')

    file_name = result_data['íŒŒì¼ëª…']
    parsed_data = result_data.get('í‰ê°€ê²°ê³¼_ë¶„ì„', {})
    
    document.add_heading('AI ì—ì„¸ì´ í‰ê°€ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ', level=1)
    p = document.add_paragraph(); p.add_run('í‰ê°€ëª…: ').bold = True; p.add_run(eval_name)
    p = document.add_paragraph(); p.add_run('í‰ê°€ì¼ì: ').bold = True; p.add_run(eval_date.strftime('%Y-%m-%d'))
    p = document.add_paragraph(); p.add_run('íŒŒì¼ëª… (í•™ìƒ): ').bold = True; p.add_run(file_name)
    p = document.add_paragraph(); p.add_run('ì´ì : ').bold = True; p.add_run(f"{parsed_data.get('ì´ì ', 'N/A')} ì ")
    document.add_heading('ğŸ’¬ ì¢…í•© í‰ê°€', level=2)
    document.add_paragraph(parsed_data.get('ì¢…í•© í‰ê°€', 'ë‚´ìš© ì—†ìŒ'))
    document.add_heading('ğŸ’¯ í•­ëª©ë³„ ìƒì„¸ í‰ê°€', level=2)
    itemized_scores = parsed_data.get('í•­ëª©ë³„ í‰ê°€', {})
    if itemized_scores:
        for item_name, details in itemized_scores.items():
            document.add_heading(f"{item_name} ({details.get('ì ìˆ˜', 'N/A')} / {details.get('ë°°ì ', 'N/A')})", level=3)
            p = document.add_paragraph(); p.add_run('í‰ê°€ ì´ìœ : ').bold = True; p.add_run(details.get('ì´ìœ ', 'ë‚´ìš© ì—†ìŒ'))
    
    doc_buffer = io.BytesIO()
    document.save(doc_buffer)
    doc_buffer.seek(0)
    return doc_buffer

# --- ğŸ–¥ï¸ 2. ë©”ì¸ ì•± ì‹¤í–‰ ---
if check_password():
    # --- AI ì´ˆê¸°í™” ---
    try:
        if "GOOGLE_AI_API_KEY" in st.secrets:
            genai.configure(api_key=st.secrets["GOOGLE_AI_API_KEY"])
        else:
            st.warning("Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            st.stop()
    except Exception as e:
        st.error(f"Google AI API í‚¤ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

    # --- âœ¨ ì œëª© ë° í”„ë¡œí•„ ì‚¬ì§„ ---
    st.markdown("""<style>.profile-img img {width: 90px; height: 90px; border-radius: 50%; object-fit: cover; margin-top: 10px; margin-bottom: 10px;}</style>""", unsafe_allow_html=True)
    col1, col2 = st.columns([1, 5])
    with col1:
        image_file = 'my_photo.jpg' # âš ï¸ ì‹¤ì œ ì‚¬ì§„ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
        if os.path.exists(image_file):
            with open(image_file, "rb") as f:
                img_base64 = base64.b64encode(f.read()).decode()
                st.markdown(f'<div class="profile-img"><img src="data:image/jpeg;base64,{img_base64}"></div>', unsafe_allow_html=True)
    with col2:
        st.title("AI ì—ì„¸ì´ í‰ê°€ í”Œë«í¼")
        st.caption("Ally êµìˆ˜ì˜ ë§ì¶¤í˜• AI í‰ê°€ ë„ìš°ë¯¸")

    # --- ğŸ“‚ ë°ì´í„°ë² ì´ìŠ¤(JSON íŒŒì¼) ê´€ë¦¬ í•¨ìˆ˜ ---
    HISTORY_FILE = 'evaluation_history.json'
    def load_history():
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                try: return json.load(f)
                except json.JSONDecodeError: return []
        return []
    def save_history(history_data):
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, ensure_ascii=False, indent=4)

    history = load_history()
    with st.sidebar:
        st.header("ğŸ“š í‰ê°€ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°")
        if history:
            history_options = {f"{item['í‰ê°€ëª…']} ({item['í‰ê°€ì¼ì']})": i for i, item in enumerate(history)}
            selected_history = st.selectbox("ë¶ˆëŸ¬ì˜¬ í‰ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”.", options=list(history_options.keys()))
            if st.button("ì„ íƒí•œ í‰ê°€ ê¸°ì¤€ ë¶ˆëŸ¬ì˜¤ê¸°"):
                selected_index = history_options[selected_history]
                st.session_state.criteria_list = history[selected_index]['í‰ê°€ê¸°ì¤€']
                st.success(f"'{selected_history}'ì˜ í‰ê°€ ê¸°ì¤€ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                st.rerun()
        else: st.info("ì €ì¥ëœ í‰ê°€ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    # --- ğŸ§  AI ì‘ë‹µ ë¶„ì„ í•¨ìˆ˜ ---
    def parse_ai_response(response_text, criteria_list):
        parsed_data = {}
        try:
            summary_match = re.search(r"\[ì¢…í•© í‰ê°€\]\s*([\s\S]*?)\s*\[í•­ëª©ë³„ í‰ê°€\]", response_text)
            parsed_data['ì¢…í•© í‰ê°€'] = summary_match.group(1).strip() if summary_match else "ì¢…í•© í‰ê°€ ì¶”ì¶œ ì‹¤íŒ¨"
            scores = {}
            total_score = 0
            for criterion in criteria_list:
                item_name = criterion['í•­ëª©']
                max_score = criterion['ë°°ì ']
                pattern = re.compile(rf"- {re.escape(item_name)}:\s*\[.*?(\d+)\s*ì \]\s*([\s\S]*?)(?=\n- |\Z)")
                match = pattern.search(response_text)
                if match:
                    score = int(match.group(1))
                    reason = match.group(2).strip()
                    scores[item_name] = {"ì ìˆ˜": score, "ì´ìœ ": reason, "ë°°ì ": max_score}
                    total_score += score
                else:
                    scores[item_name] = {"ì ìˆ˜": 0, "ì´ìœ ": "í•­ëª©ë³„ í‰ê°€ ì¶”ì¶œ ì‹¤íŒ¨", "ë°°ì ": max_score}
            parsed_data['í•­ëª©ë³„ í‰ê°€'] = scores
            parsed_data['ì´ì '] = total_score
        except Exception as e:
            return {"ì¢…í•© í‰ê°€": f"AI ì‘ë‹µ ë¶„ì„ ì‹¤íŒ¨: {e}", "í•­ëª©ë³„ í‰ê°€": {}, "ì´ì ": 0}
        return parsed_data

    # --- UI ë¡œì§ ---
    st.subheader("ğŸ“ 1ë‹¨ê³„: í‰ê°€ ì •ë³´ ì…ë ¥")
    eval_name = st.text_input("í‰ê°€ëª…", placeholder="ì˜ˆ: 2025ë…„ 1í•™ê¸° ì¤‘ê°„ ë…¼ìˆ  í‰ê°€")
    eval_date = st.date_input("í‰ê°€ì¼ì", datetime.date.today())

    with st.expander("ğŸ“Š 2ë‹¨ê³„: í‰ê°€ ê¸°ì¤€ ì„¤ì •", expanded=True):
        if 'criteria_list' not in st.session_state:
            st.session_state.criteria_list = [{"í•­ëª©": "ë‚´ìš©ì˜ ì¶©ì‹¤ì„±", "ë°°ì ": 40, "ê¸°ì¤€": "ì£¼ì œì— ëŒ€í•œ ì´í•´ê°€ ê¹Šê³ , ê·¼ê±°ê°€ íƒ€ë‹¹í•˜ë©° ë‚´ìš©ì´ í’ë¶€í•œê°€?"},
                                             {"í•­ëª©": "ë…¼ë¦¬ì  êµ¬ì¡°", "ë°°ì ": 30, "ê¸°ì¤€": "ì„œë¡ , ë³¸ë¡ , ê²°ë¡ ì˜ êµ¬ì¡°ê°€ ëª…í™•í•˜ê³ , ë¬¸ë‹¨ ê°„ì˜ ì—°ê²°ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?"},
                                             {"í•­ëª©": "í‘œí˜„ì˜ ì •í™•ì„±", "ë°°ì ": 30, "ê¸°ì¤€": "ì–´íœ˜ ì‚¬ìš©ì´ ì ì ˆí•˜ê³ , ë¬¸ë²• ë° ë§ì¶¤ë²• ì˜¤ë¥˜ê°€ ì—†ëŠ”ê°€?"}]
        for i, criterion in enumerate(st.session_state.criteria_list):
            st.markdown("---")
            col1, col2, col3 = st.columns([3, 1, 1])
            criterion['í•­ëª©'] = col1.text_input(f"í•­ëª© #{i+1}", value=criterion['í•­ëª©'], key=f"item_{i}")
            criterion['ë°°ì '] = col2.number_input(f"ë°°ì  #{i+1}", min_value=0, max_value=100, value=criterion['ë°°ì '], key=f"score_{i}")
            with col3:
                st.write(""); st.write("")
                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{i}"):
                    st.session_state.criteria_list.pop(i)
                    st.rerun()
            criterion['ê¸°ì¤€'] = st.text_area(f"ì„¸ë¶€ ê¸°ì¤€ #{i+1}", value=criterion['ê¸°ì¤€'], key=f"desc_{i}", height=100)
        if st.button("â• í‰ê°€ í•­ëª© ì¶”ê°€"):
            st.session_state.criteria_list.append({"í•­ëª©": "", "ë°°ì ": 10, "ê¸°ì¤€": ""})
            st.rerun()

    st.subheader("ğŸ“„ 3ë‹¨ê³„: ì—ì„¸ì´ íŒŒì¼ ì—…ë¡œë“œ ë° í‰ê°€ ì‹¤í–‰")
    uploaded_essays = st.file_uploader("í‰ê°€í•  í•™ìƒë“¤ì˜ ì—ì„¸ì´ PDF íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['pdf'], accept_multiple_files=True)

    if st.button("ğŸš€ ëª¨ë“  íŒŒì¼ í‰ê°€ ì‹œì‘", key="start_eval_button"):
        if not eval_name:
            st.error("âš ï¸ 1ë‹¨ê³„ì—ì„œ í‰ê°€ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif not uploaded_essays:
            st.warning("âš ï¸ 3ë‹¨ê³„ì—ì„œ í‰ê°€í•  ì—ì„¸ì´ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            results = []
            progress_bar = st.progress(0, text="í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            for i, essay_file in enumerate(uploaded_essays):
                progress_text = f"í‰ê°€ ì§„í–‰ ì¤‘: {essay_file.name} ({i+1}/{len(uploaded_essays)})"
                progress_bar.progress((i + 1) / len(uploaded_essays), text=progress_text)
                try:
                    full_text = ""
                    with pdfplumber.open(essay_file) as pdf:
                        full_text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])
                    if not full_text.strip():
                        results.append({"íŒŒì¼ëª…": essay_file.name, "í‰ê°€ê²°ê³¼_ì›ë³¸": "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨", "í‰ê°€ê²°ê³¼_ë¶„ì„": {}})
                        continue
                    criteria_str = "\n".join([f"- í•­ëª©: {c['í•­ëª©']}, ë°°ì : {c['ë°°ì ']}, ê¸°ì¤€: {c['ê¸°ì¤€']}" for c in st.session_state.criteria_list])
                    output_format_str = "\n".join([f"- {c['í•­ëª©']}: [{c['ë°°ì ']}ì  ë§Œì ì— 00ì ]\n(ì ìˆ˜ ë¶€ì—¬ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì„œìˆ í•´ì£¼ì„¸ìš”.)" for c in st.session_state.criteria_list])
                    prompt = f"""
                    ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë…¼ìˆ  í‰ê°€ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í•™ìƒì˜ ì—ì„¸ì´ë¥¼ ì•„ë˜ì˜ í‰ê°€ ê¸°ì¤€ì— ë”°ë¼ ë¶„ì„í•˜ê³  ì±„ì í•´ì£¼ì„¸ìš”.
                    **í‰ê°€ ê¸°ì¤€:**\n{criteria_str}
                    **í•™ìƒ ì—ì„¸ì´:**\n---\n{full_text}\n---
                    **ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì— ë§ì¶° ì‘ë‹µí•´ì£¼ì„¸ìš”. ê° í•­ëª©ì€ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.):**
                    [ì¢…í•© í‰ê°€]
                    (ì—ì„¸ì´ ì „ì²´ì— ëŒ€í•œ ê°•ì ê³¼ ê°œì„ ì ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ í”¼ë“œë°±ì„ ì„œìˆ í•´ì£¼ì„¸ìš”.)
                    [í•­ëª©ë³„ í‰ê°€]
                    {output_format_str}
                    """
                    model = genai.GenerativeModel('gemini-1.5-flash')
                    response = model.generate_content(prompt, request_options={'timeout': 300})
                    parsed_result = parse_ai_response(response.text, st.session_state.criteria_list)
                    results.append({"íŒŒì¼ëª…": essay_file.name, "í‰ê°€ê²°ê³¼_ì›ë³¸": response.text, "í‰ê°€ê²°ê³¼_ë¶„ì„": parsed_result})
                    time.sleep(1)
                except Exception as e:
                    st.error(f"{essay_file.name} í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    results.append({"íŒŒì¼ëª…": essay_file.name, "í‰ê°€ê²°ê³¼_ì›ë³¸": f"ì˜¤ë¥˜ ë°œìƒ: {e}", "í‰ê°€ê²°ê³¼_ë¶„ì„": {}})
            st.session_state['evaluation_results'] = results

    # --- ğŸ“ˆ 4. í‰ê°€ ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ ---
    if 'evaluation_results' in st.session_state and st.session_state['evaluation_results']:
        st.subheader("ğŸ“ˆ 4ë‹¨ê³„: í‰ê°€ ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ")
        results_data = st.session_state['evaluation_results']
        criteria_names = [c['í•­ëª©'] for c in st.session_state.criteria_list]
        summary_data = []
        for result in results_data:
            row = {'íŒŒì¼ëª…': result['íŒŒì¼ëª…']}
            parsed_scores = result.get('í‰ê°€ê²°ê³¼_ë¶„ì„', {}).get('í•­ëª©ë³„ í‰ê°€', {})
            for name in criteria_names:
                row[name] = parsed_scores.get(name, {}).get('ì ìˆ˜', 'N/A')
            row['ì´ì '] = result.get('í‰ê°€ê²°ê³¼_ë¶„ì„', {}).get('ì´ì ', 'N/A')
            summary_data.append(row)
        summary_df = pd.DataFrame(summary_data)
        st.markdown("### ğŸ“Š ì „ì²´ ì ìˆ˜ ìš”ì•½í‘œ")
        st.dataframe(summary_df)

        col1, col2 = st.columns(2)
        with col1:
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                summary_df.to_excel(writer, index=False, sheet_name='ì „ì²´ ì ìˆ˜ ìš”ì•½')
            st.download_button(label="ğŸ“¥ ì—‘ì…€ ìš”ì•½í‘œ ë‹¤ìš´ë¡œë“œ", data=excel_buffer.getvalue(), file_name=f"{eval_name}_ì „ì²´ìš”ì•½.xlsx", mime="application/vnd.ms-excel", key="download_excel")
        with col2:
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w') as zipf:
                for result in results_data:
                    report_docx_buffer = generate_report_docx(result, eval_name, eval_date)
                    zipf.writestr(f"{os.path.splitext(result['íŒŒì¼ëª…'])[0]}_ìƒì„¸ë³´ê³ ì„œ.docx", report_docx_buffer.getvalue())
            st.download_button(label="ğŸ—‚ï¸ ëª¨ë“  ìƒì„¸ ë³´ê³ ì„œ (ZIP) ë‹¤ìš´ë¡œë“œ", data=zip_buffer.getvalue(), file_name=f"{eval_name}_ìƒì„¸ë³´ê³ ì„œ.zip", mime="application/zip", key="download_zip")

        st.markdown("### ğŸ“ í•™ìƒë³„ ìƒì„¸ í‰ê°€")
        for result in results_data:
            with st.expander(f"ğŸ“„ {result['íŒŒì¼ëª…']} ìƒì„¸ ê²°ê³¼ ë³´ê¸°"):
                # í™”ë©´ í‘œì‹œëŠ” ë§ˆí¬ë‹¤ìš´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
                st.markdown(generate_report_markdown(result))
                
                # ë‹¤ìš´ë¡œë“œëŠ” ì›Œë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©
                report_docx_buffer = generate_report_docx(result, eval_name, eval_date)
                st.download_button(
                    label="ğŸ“‹ ê°œë³„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (.docx)",
                    data=report_docx_buffer.getvalue(),
                    file_name=f"{os.path.splitext(result['íŒŒì¼ëª…'])[0]}_ìƒì„¸ë³´ê³ ì„œ.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    key=f"download_{result['íŒŒì¼ëª…']}"
                )
        
        if st.button("ğŸ’¾ í˜„ì¬ í‰ê°€ë¥¼ ê¸°ë¡ì— ì €ì¥", key="save_history_button"):
            new_history_item = {
                "í‰ê°€ëª…": eval_name,
                "í‰ê°€ì¼ì": eval_date.strftime("%Y-%m-%d"),
                "í‰ê°€ê¸°ì¤€": st.session_state.criteria_list,
                "í‰ê°€ê²°ê³¼": results_data
            }
            history.append(new_history_item)
            save_history(history)
            st.success("í˜„ì¬ í‰ê°€ê°€ ê¸°ë¡ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
